{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction to Prometheus","text":""},{"location":"#what-is-promethues","title":"What is Promethues","text":"<p>Protmetheus is an open-source monitoring tool, mostly written in the 'Go' language by SoundCloud. It is specifically made for short-term monitoring. It has multi-dimensional data with time-series which is identified by Metric Name that are represented in Key/Value Pairs (Key:Value). It primarily pulls metric from an endpoint but there is also a Push gateway involved in some deployments.</p> <ul> <li>Prometheus has a strong suite in Machine Centric Monitoring</li> <li>Even a stronger suite in Dynamic service-oriented architectures (microservices)</li> <li>It is designed for reliability. Standalone and Independent of the larger architecture, totally decoupled from everything</li> </ul>"},{"location":"#what-isnt-prometheus","title":"What isn't Prometheus","text":"<ul> <li>It is not a long term metric storage solution</li> <li>Does not have a 100% accuracy in metrics</li> <li>Not meant for deep, detailed metrics. Instead, it is good at -<ul> <li>Summarizing Metrics</li> </ul> </li> <li>It is not a push oriented metrics system as its main strength is pulling metrics</li> </ul>"},{"location":"#features-overview","title":"Features Overview","text":""},{"location":"#core-set","title":"Core Set","text":"<ul> <li>Time series Data Identification<ul> <li>Metric name</li> <li>Key Value Pairs</li> </ul> </li> <li>Functional Query Language; built on a specific, custom, PromQL tool. PromQL performs aggregation in real-time. These can be graphed and consumed by external systems via HTTP API.</li> <li>Pre-configured rules can speed up longer queries.</li> <li>It also provides flexible graphing and dashboarding using PromDash; a GUI based builder having an SQL backend.</li> <li>HTTP API, which is involved in the prometheus server and exists as <code>/api/v1</code></li> </ul>"},{"location":"#promql-rules","title":"PromQL Rules","text":"<ul> <li>In the configuration file -recording rules are referred to via a file containing their configuration. So we have <code>rule_files</code> :<ul> <li><code>prometheus.rules.yaml</code></li> </ul> </li> </ul> <pre><code>groups:\n  # name of the rule\n- name: \n  rules:\n    # the rules by recording\n  - record: \n    # the expressions we want to evaluate them against\n    expr: \n</code></pre> <ul> <li>Prometheus is non-reliant on a distributed storage system. As a result, it gets high througput using the on-node storage.</li> <li>Non-meant as a long term storage solution. Ideally for 3-6 months of storage. And then engineers might want to upload the data to Thanos.</li> <li>Prometheus collects its metrics using HTTP Pulls (one URI per exporter)</li> <li>Prometheus scrapes these endpoints and the endpoints can either be defined or discovered</li> </ul>"},{"location":"#defined-discovered","title":"Defined &amp; Discovered","text":"<ul> <li>Prometheus collects metrics over HTTP Pulls, which can either be -<ul> <li>Defined: Statically configured in the YAML file</li> <li>Discovered: Automatically discovered by Prometheus using its' DNS discovery service</li> </ul> </li> </ul> <pre><code># Defined \n- job name: prometheus\n  honor_timestamps: true\n  scrape_interval: 5s\n  scrap_timeout: 5s\n  metrics_path: /metrics\n  scheme: http\n  static_configs:\n  - targets:\n    - localhost: 9090\n</code></pre>"},{"location":"#pushing","title":"Pushing","text":"<ul> <li>Pushing is available through the PushGateway. It is used for non-scrapable components and for short-lived jobs.</li> <li>It can also be used to present metrics to prometheus for pulling. You can think of this as an intermediary server that prometheus can pull from.</li> </ul>"},{"location":"#components","title":"Components","text":""},{"location":"#pushgateway","title":"PushGateway","text":"<p>PushGateway is best suited for service-level jobs because when we have an intermediary pushing the metrics, it can also be a single point of failure for those metrics. If we build our critical layers on system level information and our PushGateway failed, so would our alerting. This is why PushGateway needs to act for only service short-lived jobs.</p> <p>The native health monitoring that Prometheus generates is not generated on PushGateway instances. That's because the inteneded purpose of this metrics is jobs to push and then exit</p> <p>Metrics pushed to the PushGateway are not destroyed which Prometheus usually does. So they persist even after the jobs are exited. So they will be exposed to Prometheus forever until they are manually deleted via the PushGateway's API. </p>"},{"location":"#prometheus-server","title":"Prometheus Server","text":"<p>The prometheus server may look monolithic in nature but it has several components.</p> <ul> <li>Retrieval Worker - Goes out and scrapes the endpoints</li> <li>The Storage Database<ul> <li>Connects to local Node Storage</li> <li>Time Series Database</li> </ul> </li> <li>HTTP Server <ul> <li>Dashboarding</li> <li>API - Responses are in JSON</li> <li>Plug into our Alertmanager</li> </ul> </li> </ul> <p>But how is Prometheus Configured? Let's look at a Prometheus config file. We will divide the prometheus config file into several blocks -</p> <pre><code>global:\n    scrape_interval: 15s\n    scrape_timeout: 10s\n    evaluation_interval: 1m\n    external_labels:\n        monitor: Cloudcademy-Prom-Demo\n\nrule_files:\n- prometheus.rules.yaml\n\nscrape_configs:\n# we can mention specific jobs here \n# this job is monitoring prometheus after every 5s from the /metrics path \n# and it is hosted on 9090 port\n- job name: prometheus\n  honor_timestamps: true\n  scrape_interval: 5s\n  scrap_timeout: 5s\n  metrics_path: /metrics\n  scheme: http\n  static_configs:\n  - targets:\n    - localhost: 9090\n\n- job_name: Prom1-node\n  honor_timestamps: true\n  scrape_interval: 5s\n  scrap_timeout: 5s\n  metrics_path: /metrics\n  scheme: http\n  static_configs:\n  - targets:\n    - localhost: 8080\n    - localhost: 8081\n    labels:\n      group: CloudAcademy-Prod\n  - targets:\n    - localhost: 8082\n    labels:\n      group: CloudAcademy-Dev\n</code></pre>"},{"location":"#alertmanager","title":"Alertmanager","text":"<p>Alertmanager handles alerts sent by client applications, sends them along their way and routes them to the correct receiver, whether that be - Email, PagerDuty etc. </p> <p>Grouping: It also has ways to group alerts into a single notification. So you are not alerted every single time an instance maybe failing. </p> <p>Inhibition: It also has the ability to prevent alerts from failing if another alert is going on. For example - If alert X is alerting, don't turn trigger alert Y. This could be useful in situations for example if a whole cluster is down, we don't need alerts for every instances within that cluster and their alerts. </p> <p>Silences: There is also ability to mute alerts for given period of time. </p> <p>High-Availability: There is high availability for multi-cluster support available through a command-line plug</p>"},{"location":"#exporters","title":"Exporters","text":"<p>Exporters are open-source generally and they are tailored for Prometheus. They - </p> <ul> <li>Grab metrics for Prometheus</li> <li>Alter those metrics into a Prometheus format<ul> <li>Using a client library such as - GO, Java or Scala, Python, Ruby</li> </ul> </li> <li>After this they typically start a web server for themselves to be scraped upon</li> </ul>"},{"location":"grafana/","title":"Grafana","text":"<p>Grafana is an open source analytics and interactive visualization web application, providing charts, graphs, and alerts for monitoring and observability requirements. You'll configure Grafana to connect to Prometheus. </p> <ul> <li>Using Helm, install Grafana using the publicly available Grafana Helm Chart. You will deploy Grafana into the monitoring namespace -</li> </ul> <pre><code>{\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\nhelm install grafana --namespace monitoring grafana/grafana --version 6.1.14\n}\n</code></pre> <ul> <li>Confirm that the Grafana deployment has been rolled out successfully. In the terminal execute the following command:</li> </ul> <pre><code>kubectl get deployment grafana -n monitoring -w\n</code></pre> <ul> <li>The Grafana web admin interface now needs to be exposed to the Internet. To do so, create a new NodePort based Service, exposing the web admin interface on port 30300. In the terminal execute the following command:</li> </ul> <pre><code>{\nkubectl expose deployment grafana --type=NodePort --name=grafana-main --port=30300 --target-port=3000 -n monitoring\nkubectl patch service grafana-main -n monitoring -p '{\"spec\":{\"ports\":[{\"nodePort\": 30300, \"port\": 30300, \"protocol\": \"TCP\", \"targetPort\": 3000}]}}'\n}\n</code></pre> <ul> <li>Extract the default admin password which will be required to login. In the terminal execute the following command:</li> </ul> <pre><code>kubectl get secret --namespace monitoring grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n</code></pre> <ul> <li>Get the public IP address of the Kubernetes cluster that Grafana has been deployed into. In the terminal execute the following command:</li> </ul> <pre><code>export | grep K8S_CLUSTER_PUBLICIP\n</code></pre> <ul> <li>Having successfully authenticated, the Welcome to Grafana home page is displayed. Within the Data Sources section, click on the Add your first data source option. In the Add data source view, select the Prometheus option by clicking on it's Select button. </li> <li>In the Data Sources / Prometheus configuration view update the HTTP URL to be the same URL that you previously used to browse to the Prometheus web admin interface. Leave all other default settings as is. In particular its important to leave the Name field set to Prometheus. Complete the Prometheus data source setup by clicking  on the Save &amp; Test button at the bottom. </li> <li>In the IDE, open the project/code/grafana directory and click on the dashboard.json file to open it within the editor pane. In the editor pane, select all of the configuration and copy it to the clipboard.</li> <li>Return to Grafana and this time select the Create icon (+) on the main left hand side menu, and then select the dashboard Import option </li> <li>In the Import view, paste in the copied Grafana dashboard json into the Import via panel json area and then click the Load button</li> <li>Under Import Options, accept all defaults without changing anything, and then click the Import button</li> <li>Grafana will now load the prebuilt dashboard and start rendering visualisations using live monitoring data streams taken from Prometheus. The dashboard view automatically refreshes every 5 seconds</li> </ul>"},{"location":"prometheus-install/","title":"Prometheus Installation","text":"<ul> <li>Create a new <code>monitoring</code> namespace within the cluster - </li> </ul> <pre><code>kubectl create ns monitoring\n</code></pre> <ul> <li>Using Helm, install Prometheus using the publicly available Prometheus Helm Chart. Deploy Prometheus into the monitoring namespace within the lab provided cluster. In the terminal execute the following commands:</li> </ul> <pre><code>{\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add stable https://charts.helm.sh/stable\nhelm repo update\nhelm install prometheus --namespace monitoring --values ./code/prometheus/values.yml prometheus-community/prometheus --version 13.0.0\n}\n</code></pre> <ul> <li>Confirm that Prometheus has been successfully rolled out within the cluster. In the terminal execute the following command:</li> </ul> <pre><code>kubectl get deployment -n monitoring -w\n</code></pre> <ul> <li>Patch the Prometheus Node Exporter DaemonSet to ensure that Prometheus can collect Memory and CPU node metrics. In the terminal execute the following command:</li> </ul> <pre><code>kubectl patch daemonset prometheus-node-exporter -n monitoring -p '{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"prometheus.io/scrape\": \"true\"}}}}}'\n</code></pre> <ul> <li>The Prometheus web admin interface now needs to be exposed to the Internet so that you can browse to it. To do so, create a new NodePort based Service, and expose the web admin interface on port 30900. In the terminal execute the following command:</li> </ul> <pre><code>{\nkubectl expose deployment prometheus-server --type=NodePort --name=prometheus-main --port=30900 --target-port=9090 -n monitoring\nkubectl patch service prometheus-main -n monitoring -p '{\"spec\":{\"ports\":[{\"nodePort\": 30900, \"port\": 30900, \"protocol\": \"TCP\", \"targetPort\": 9090}]}}'\n}\n</code></pre> <ul> <li>Get the public IP address of the Kubernetes cluster that Prometheus has been deployed into. In the terminal execute the following command:</li> </ul> <pre><code>export | grep K8S_CLUSTER_PUBLICIP\n</code></pre>"}]}